{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import edlib\n",
    "from bignmf.models.snmf.standard import StandardNmf\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_ribo(file_name, reads_modifs_dict):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        index = 0\n",
    "        while line != \"\":\n",
    "            mod_clust = line.split(\"\\t\")\n",
    "            name = mod_clust[0]\n",
    "            modifs = mod_clust[1].split(\" \")\n",
    "            m = bin(int(''.join(map(str, modifs)), 2) << 1)\n",
    "            reads_modifs_dict[name] = (m, index)\n",
    "            index += 1\n",
    "            line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(reads_modifs_dict, reads_name):\n",
    "    reads_modifs_dict_subset = {}\n",
    "    sub_set = list(reads_modifs_dict.keys())\n",
    "    for i, read in enumerate(sub_set):\n",
    "        name = \"read_\" + str(i)\n",
    "        reads_name[read] = name\n",
    "        reads_modifs_dict_subset[name] = reads_modifs_dict[read][0]\n",
    "    reads_modifs_dict = reads_modifs_dict_subset.copy()\n",
    "    return reads_modifs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_function(r1, r2):\n",
    "    intersection = str(bin(int(r1[2:], 2) & int(r2[2:], 2)))[2:].count(\"1\")\n",
    "    if intersection == 0:\n",
    "        return 0\n",
    "    union = str(bin(int(r1[2:], 2) | int(r2[2:], 2)))[2:].count(\"1\")\n",
    "    return float(intersection)/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_jacc(r1, r2):\n",
    "    r1 = np.array(r1)\n",
    "    print(r1)\n",
    "    r2 = np.array(r2)\n",
    "    sum_r = np.add(r1, r2)\n",
    "    union = np.count_nonzero(sum_r)\n",
    "    inter = np.count_nonzero(sum_r == 2)\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_function_edlib(r1, r2):\n",
    "    sim = 0\n",
    "    try:\n",
    "        align_result = edlib.align(r1, r2, mode=\"PW\", task=\"path\")\n",
    "    except:\n",
    "        return sim\n",
    "    \n",
    "    distance = align_result['editDistance']\n",
    "    if distance > 0:\n",
    "        sim = 1 - (1/distance)\n",
    "    else:\n",
    "        sim = 1.0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sim_matrix(data, reads_modifs_dict):\n",
    "    i = 0\n",
    "    for k1 in reads_modifs_dict.keys():\n",
    "        i += 1\n",
    "        r1 = reads_modifs_dict[k1]\n",
    "        ind1 = int(k1[5:])\n",
    "        for k2 in reads_modifs_dict.keys():\n",
    "            r2 = reads_modifs_dict[k2]\n",
    "            ind2 = int(k2[5:])\n",
    "            if data[ind1][ind2] >= 0:\n",
    "                continue\n",
    "            if k1 == k2:\n",
    "                sim = 1.0\n",
    "            else:\n",
    "                sim = similarity_function(r1, r2)\n",
    "            data[ind1][ind2] = sim\n",
    "            data[ind2][ind1] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF_iteration(num_clusters, data, names, clusters_freq, clusters_reads, inertia_array, threshold):\n",
    "    iteration = 0\n",
    "    razvrstani = []\n",
    "\n",
    "    df = pd.DataFrame(data, columns=names, index=names)\n",
    "    \n",
    "    while len(razvrstani) < len(data[0]):\n",
    "        iteration += 1\n",
    "        model = NMF(n_components=num_clusters, init='random', random_state=0, tol=1e-3, max_iter=2000)\n",
    "        W = model.fit_transform(df)\n",
    "        H = model.components_\n",
    "        err = model.reconstruction_err_\n",
    "    \n",
    "        nerazvrstani = []\n",
    "        novi_razvrstani = []\n",
    "        klasteri_novi_razvrstani = []\n",
    "        for i, index in enumerate(df.index.values.tolist()):\n",
    "            max_index = -1\n",
    "            max_value = -1.\n",
    "            for j in range(len(H)):\n",
    "                if H[j][i] > max_value:\n",
    "                    max_index = j\n",
    "                    max_value = H[j][i]\n",
    "        \n",
    "            for_cluster = True\n",
    "            for j in range(len(H)):\n",
    "                if j == max_index:\n",
    "                    continue\n",
    "                if max_value - H[j][i] < threshold:\n",
    "                    for_cluster = False\n",
    "                    break\n",
    "            if for_cluster:\n",
    "                clusters_freq[max_index] += 1\n",
    "                cluster_list = clusters_reads[max_index]\n",
    "                cluster_list.append(index)\n",
    "                clusters_reads[max_index] = cluster_list\n",
    "                razvrstani.append(index)\n",
    "                novi_razvrstani.append(index)\n",
    "                klasteri_novi_razvrstani.append(max_index)\n",
    "            else:\n",
    "                nerazvrstani.append(index)\n",
    "        if len(novi_razvrstani) == 0:\n",
    "            break\n",
    "        \n",
    "        for i,read in enumerate(novi_razvrstani):\n",
    "            centroid = [item[klasteri_novi_razvrstani[i]] for item in W]\n",
    "            inertia = np.linalg.norm(np.array(df[read].values) - np.array(centroid))\n",
    "            inertia_array.append(inertia)\n",
    "        \n",
    "        df = df.drop(novi_razvrstani)\n",
    "        df = df.drop(novi_razvrstani, axis=1)\n",
    "    \n",
    "        print(\"Number of not clustered reads: \" + str(len(nerazvrstani)))\n",
    "    \n",
    "    for i, index in enumerate(df.index.values.tolist()):\n",
    "        max_index = -1\n",
    "        max_value = -1.\n",
    "        for j in range(len(H)):\n",
    "            if H[j][i] > max_value:\n",
    "                max_index = j\n",
    "                max_value = H[j][i]\n",
    "        clusters_freq[max_index] += 1\n",
    "        cluster_list = clusters_reads[max_index]\n",
    "        cluster_list.append(index)\n",
    "        clusters_reads[max_index] = cluster_list\n",
    "        razvrstani.append(index)\n",
    "        \n",
    "        centroid = [item[max_index] for item in W]\n",
    "        inertia = np.linalg.norm(np.array(df[index].values) - np.array(centroid))\n",
    "        inertia_array.append(inertia)\n",
    "\n",
    "    print(clusters_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(file_name, clusters_reads, reads_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for cluster, reads in clusters_reads.items():\n",
    "            for read in reads:\n",
    "                for r, name in reads_name.items():\n",
    "                    if name == read:\n",
    "                        read_name = r\n",
    "                        break\n",
    "                line = read_name + \" : \" + str(cluster) + \"\\n\"\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_modifs_dict = {}\n",
    "read_file_ribo(\"MPRS21_all.txt\", reads_modifs_dict)\n",
    "reads_name = {}\n",
    "reads_modifs_dict = prepare_data(reads_modifs_dict, reads_name)\n",
    "data = np.full((len(list(reads_modifs_dict.keys())), len(list(reads_modifs_dict.keys()))), -1.0)\n",
    "calculate_sim_matrix(data, reads_modifs_dict)\n",
    "\n",
    "clusters_freq = {0:0, 1:0}\n",
    "clusters_reads = {0:[], 1:[]}\n",
    "inertia_array = []\n",
    "\n",
    "threshold = 0.1\n",
    "NMF_algorithm(2, data, list(reads_modifs_dict.keys()), clusters_freq, clusters_reads, inertia_array, threshold)\n",
    "inertia_array = np.array(inertia_array)\n",
    "\n",
    "save_to_file(\"MPRS21_clusters_NMF.txt\", clusters_reads, reads_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
